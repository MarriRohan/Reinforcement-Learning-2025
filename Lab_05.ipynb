{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4TCtsFTezkBxI+RNVvErc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarriRohan/Reinforcement-Learning-2025/blob/main/Lab_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlTfBjpg1M4S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64ad8319"
      },
      "source": [
        "# Task\n",
        "Implement Q-learning for the FrozenLake environment from OpenAI Gym in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0dc456f"
      },
      "source": [
        "## Install necessary libraries\n",
        "\n",
        "### Subtask:\n",
        "Install the `gym` library to access the OpenAI Gym environments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ff5369b"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires installing the `gym` library, which can be done using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87fdf20e",
        "outputId": "958fa287-0223-4740-a83c-c7b6d6fd3e7f"
      },
      "source": [
        "%pip install gym"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym) (0.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b27004e"
      },
      "source": [
        "## Set up the environment\n",
        "\n",
        "### Subtask:\n",
        "Import and set up the FrozenLake environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07f8d2ad"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the gym library and create a FrozenLake environment instance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a9042d4",
        "outputId": "b924cbcd-c11f-49c7-eeff-6fb6300fa475"
      },
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
        "print(\"Environment created successfully.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment created successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.12/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fda69f5b"
      },
      "source": [
        "## Initialize the q-table\n",
        "\n",
        "### Subtask:\n",
        "Create and initialize a Q-table (a NumPy array) with zeros or random values. The dimensions of the Q-table will be (number of states, number of actions).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56f6b936"
      },
      "source": [
        "**Reasoning**:\n",
        "Create and initialize the Q-table with zeros using the number of states and actions from the environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7e43ce6",
        "outputId": "92dd55ba-b314-4b4b-ed23-423e1ce4b299"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "n_states = env.observation_space.n\n",
        "n_actions = env.action_space.n\n",
        "q_table = np.zeros((n_states, n_actions))\n",
        "\n",
        "print(q_table.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a846a78"
      },
      "source": [
        "## Implement the q-learning algorithm\n",
        "\n",
        "### Subtask:\n",
        "Implement the q-learning algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7755299c"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the main Q-learning training loop, including episode iteration, action selection using epsilon-greedy policy, Q-value update, and epsilon decay as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "b8e008b5",
        "outputId": "41f8d5ce-8a93-4a3f-d80a-b761f7715737"
      },
      "source": [
        "# Define hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.6  # Discount factor\n",
        "epsilon = 0.1  # Exploration rate\n",
        "n_episodes = 10000  # Number of training episodes\n",
        "epsilon_decay_rate = 0.99\n",
        "\n",
        "# Training loop\n",
        "for episode in range(n_episodes):\n",
        "    state = env.reset()[0]  # Reset environment and get initial state\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Epsilon-greedy policy\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state, :])  # Exploit learned values\n",
        "\n",
        "        # Take action and observe reward and next state\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        # Q-learning update\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (reward + gamma * np.max(q_table[next_state, :]) - q_table[state, action])\n",
        "\n",
        "        # Update current state\n",
        "        state = next_state\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon *= epsilon_decay_rate\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'int' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4201729799.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Reset environment and get initial state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0723d7b6"
      },
      "source": [
        "**Reasoning**:\n",
        "The error `TypeError: 'int' object is not subscriptable` in `state = env.reset()[0]` indicates that `env.reset()` is returning an integer instead of a tuple or list from which we can extract the state. This is likely due to a change in the gym API. I need to update how the state is retrieved from `env.reset()`. I will also regenerate the full code block to fix this error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "KopCM7af4WIA",
        "outputId": "fc82fc5c-d751-4667-d634-12a5f39f85b8"
      },
      "source": [
        "# Define hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.6  # Discount factor\n",
        "epsilon = 0.1  # Exploration rate\n",
        "n_episodes = 10000  # Number of training episodes\n",
        "epsilon_decay_rate = 0.99\n",
        "\n",
        "# Training loop\n",
        "for episode in range(n_episodes):\n",
        "    # Reset environment and get initial state - Handle API change\n",
        "    state, info = env.reset()\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Epsilon-greedy policy\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state, :])  # Exploit learned values\n",
        "\n",
        "        # Take action and observe reward and next state\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "\n",
        "        # Q-learning update\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (reward + gamma * np.max(q_table[next_state, :]) - q_table[state, action])\n",
        "\n",
        "        # Update current state\n",
        "        state = next_state\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon *= epsilon_decay_rate\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable int object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1230540133.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Reset environment and get initial state - Handle API change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2534bc31"
      },
      "source": [
        "**Reasoning**:\n",
        "The error `TypeError: cannot unpack non-iterable int object` in `state, info = env.reset()` indicates that `env.reset()` is still returning just an integer state, not a tuple containing state and info. This means the previous fix for the API change was incorrect for this specific gym version or environment. I will try retrieving the state directly from `env.reset()` without attempting to unpack, and regenerate the full code block with this fix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDoECAQS4X_h",
        "outputId": "4c3b2cd4-4748-4cc4-ba99-0d4caf98a2a9"
      },
      "source": [
        "# Define hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.6  # Discount factor\n",
        "epsilon = 0.1  # Exploration rate\n",
        "n_episodes = 10000  # Number of training episodes\n",
        "epsilon_decay_rate = 0.99\n",
        "\n",
        "# Training loop\n",
        "for episode in range(n_episodes):\n",
        "    # Reset environment and get initial state - Handle API change\n",
        "    # Based on previous attempts, env.reset() returns just the state directly\n",
        "    state = env.reset()\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Epsilon-greedy policy\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state, :])  # Exploit learned values\n",
        "\n",
        "        # Take action and observe reward and next state\n",
        "        # Based on the error, env.step() returns 4 values: next_state, reward, done, info\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Q-learning update\n",
        "        # Ensure next_state is treated as an integer index if needed\n",
        "        if isinstance(next_state, np.ndarray):\n",
        "            next_state = next_state.item() # Convert numpy array state to scalar if necessary\n",
        "\n",
        "\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (reward + gamma * np.max(q_table[next_state, :]) - q_table[state, action])\n",
        "\n",
        "        # Update current state\n",
        "        state = next_state\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon *= epsilon_decay_rate\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65e21ed0"
      },
      "source": [
        "## Implement the q-learning algorithm - retry 1\n",
        "\n",
        "### Subtask:\n",
        "Implement the q-learning algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee464b06"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt failed due to a NumPy version incompatibility with the Gym library. To fix this, I will try installing a specific, older version of NumPy known to be compatible with the gym version being used (0.25.2). After installing the compatible NumPy version, I will re-run the Q-learning algorithm implementation code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "f0479fe2",
        "outputId": "96c1a5fb-adbe-4e58-bb6a-dd59dcd05b1d"
      },
      "source": [
        "%pip install numpy==1.23.5\n",
        "\n",
        "# Define hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.6  # Discount factor\n",
        "epsilon = 0.1  # Exploration rate\n",
        "n_episodes = 10000  # Number of training episodes\n",
        "epsilon_decay_rate = 0.99\n",
        "\n",
        "# Training loop\n",
        "for episode in range(n_episodes):\n",
        "    # Reset environment and get initial state - Handle API change\n",
        "    # Based on previous attempts, env.reset() returns just the state directly\n",
        "    state = env.reset()\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Epsilon-greedy policy\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state, :])  # Exploit learned values\n",
        "\n",
        "        # Take action and observe reward and next state\n",
        "        # Based on previous attempts, env.step() returns next_state, reward, done, truncated, info\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "\n",
        "        # Q-learning update\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (reward + gamma * np.max(q_table[next_state, :]) - q_table[state, action])\n",
        "\n",
        "        # Update current state\n",
        "        state = next_state\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon *= epsilon_decay_rate\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5.tar.gz (10.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 5, got 4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2823656420.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Take action and observe reward and next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Based on previous attempts, env.step() returns next_state, reward, done, truncated, info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Q-learning update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e96cdce4"
      },
      "source": [
        "**Reasoning**:\n",
        "The installation of NumPy 1.23.5 failed, and the traceback shows a `ValueError` during `env.step(action)` because it's returning 4 values instead of the expected 5 (next_state, reward, done, truncated, info). This indicates that the Gym version being used is an older one where `step` returns only 4 values (next_state, reward, done, info). I need to adjust the unpacking of the `env.step()` return value to match what the environment actually returns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMpFZfFQ4jfx",
        "outputId": "d41ac6cc-11e2-422f-c48e-baf075be27fc"
      },
      "source": [
        "# Define hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.6  # Discount factor\n",
        "epsilon = 0.1  # Exploration rate\n",
        "n_episodes = 10000  # Number of training episodes\n",
        "epsilon_decay_rate = 0.99\n",
        "\n",
        "# Training loop\n",
        "for episode in range(n_episodes):\n",
        "    # Reset environment and get initial state\n",
        "    # Based on previous attempts, env.reset() returns just the state directly\n",
        "    state = env.reset()\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Epsilon-greedy policy\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state, :])  # Exploit learned values\n",
        "\n",
        "        # Take action and observe reward and next state\n",
        "        # Based on the error, env.step() returns 4 values: next_state, reward, done, info\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Q-learning update\n",
        "        # Ensure next_state is treated as an integer index if needed\n",
        "        if isinstance(next_state, np.ndarray):\n",
        "            next_state = next_state.item() # Convert numpy array state to scalar if necessary\n",
        "\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (reward + gamma * np.max(q_table[next_state, :]) - q_table[state, action])\n",
        "\n",
        "        # Update current state\n",
        "        state = next_state\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon *= epsilon_decay_rate\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1490ac2"
      },
      "source": [
        "## Evaluate the agent\n",
        "\n",
        "### Subtask:\n",
        "After training, evaluate the agent's performance by running episodes with a greedy policy (no exploration) and observing the average reward or success rate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9b3e51d"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the evaluation steps as described in the instructions, including setting epsilon to 0, running evaluation episodes, calculating average reward and success rate, and printing the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "679c7a68",
        "outputId": "ca690462-5ffa-4817-a99e-d4c8b35fe7d6"
      },
      "source": [
        "# Step 1: Set epsilon to 0 for evaluation\n",
        "epsilon = 0.0\n",
        "\n",
        "# Step 2: Initialize tracking variables\n",
        "total_reward = 0\n",
        "successful_episodes = 0\n",
        "n_eval_episodes = 1000  # Step 3: Define number of evaluation episodes\n",
        "\n",
        "print(\"\\nStarting evaluation...\")\n",
        "\n",
        "# Step 4: Run evaluation loop\n",
        "for episode in range(n_eval_episodes):\n",
        "    # Reset environment\n",
        "    # Based on previous experience, env.reset() returns the state directly\n",
        "    state = env.reset()\n",
        "\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "\n",
        "    # Step loop\n",
        "    while not done:\n",
        "        # Step 4 (cont.): Choose greedy action\n",
        "        action = np.argmax(q_table[state, :])\n",
        "\n",
        "        # Step 4 (cont.): Take action\n",
        "        # Based on previous experience, env.step() returns 4 values\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Step 4 (cont.): Accumulate reward\n",
        "        episode_reward += reward\n",
        "\n",
        "        # Step 4 (cont.): Update state\n",
        "        state = next_state\n",
        "\n",
        "    # Step 4 (cont.): Check for success and accumulate total reward\n",
        "    if reward == 1.0:\n",
        "        successful_episodes += 1\n",
        "    total_reward += episode_reward\n",
        "\n",
        "# Step 5: Calculate metrics\n",
        "average_reward = total_reward / n_eval_episodes\n",
        "success_rate = successful_episodes / n_eval_episodes\n",
        "\n",
        "# Step 6: Print results\n",
        "print(f\"Evaluation finished after {n_eval_episodes} episodes.\")\n",
        "print(f\"Average reward per episode: {average_reward:.4f}\")\n",
        "print(f\"Success rate: {success_rate:.4f}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation...\n",
            "Evaluation finished after 1000 episodes.\n",
            "Average reward per episode: 0.0000\n",
            "Success rate: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa85dd2f"
      },
      "source": [
        "## Visualize results\n",
        "\n",
        "### Subtask:\n",
        "Optionally, visualize the learning progress by plotting metrics like cumulative reward per episode.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba2387f5"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary library for plotting and create a list to store cumulative rewards per episode.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7abb6871"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a list to store cumulative rewards\n",
        "cumulative_rewards = []"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4128f542"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the training loop to append the cumulative reward for each episode to the `cumulative_rewards` list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dfe397b",
        "outputId": "634d6a9e-b4a3-428e-daf1-99b0cf1c456a"
      },
      "source": [
        "# Define hyperparameters (re-defining for clarity in this step, assume they are the same as before)\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "n_episodes = 10000\n",
        "epsilon_decay_rate = 0.99\n",
        "\n",
        "# Training loop\n",
        "for episode in range(n_episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    episode_reward = 0  # Initialize reward for the current episode\n",
        "\n",
        "    while not done:\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Explore\n",
        "        else:\n",
        "            action = np.argmax(q_table[state, :])  # Exploit\n",
        "\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Accumulate reward for the episode\n",
        "        episode_reward += reward\n",
        "\n",
        "        if isinstance(next_state, np.ndarray):\n",
        "            next_state = next_state.item()\n",
        "\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (reward + gamma * np.max(q_table[next_state, :]) - q_table[state, action])\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    # Append the cumulative reward for the episode\n",
        "    cumulative_rewards.append(episode_reward)\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon *= epsilon_decay_rate\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd977309"
      },
      "source": [
        "**Reasoning**:\n",
        "Plot the cumulative rewards over episodes, add labels and a title, and display the plot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "c8c483e5",
        "outputId": "d56ad613-ec1b-4b8c-a8b9-fd8bfa8ee3d8"
      },
      "source": [
        "# Plot the cumulative reward per episode\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(cumulative_rewards)\n",
        "plt.title(\"Q-learning Training Progress: Cumulative Reward per Episode\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Cumulative Reward\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Brief analysis\n",
        "# The plot shows the cumulative reward obtained in each episode during training.\n",
        "# Observing the trend can indicate whether the agent is learning effectively.\n",
        "# An upward trend would suggest learning progress, while plateaus or fluctuations might indicate slower learning or challenges in the environment."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb135260"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The FrozenLake environment 'FrozenLake-v1' with `is_slippery=False` has 16 states and 4 possible actions.\n",
        "*   The Q-table was successfully initialized as a NumPy array of shape (16, 4) with all values set to zero.\n",
        "*   The Q-learning algorithm was implemented using a learning rate ($\\alpha$) of 0.1, a discount factor ($\\gamma$) of 0.6, an initial exploration rate ($\\epsilon$) of 0.1, and an epsilon decay rate of 0.99 over 10,000 training episodes.\n",
        "*   During the training phase, the code was adjusted to handle the specific API of the Gym environment version in use, where `env.reset()` returns the state directly and `env.step()` returns 4 values (`next_state`, `reward`, `done`, `info`).\n",
        "*   After training, the agent's performance was evaluated over 1000 episodes using a greedy policy ($\\epsilon = 0$).\n",
        "*   The evaluation showed an average reward of 0.0000 and a success rate of 0.0000, indicating that the agent did not reach the goal in any of the evaluated episodes.\n",
        "*   A plot of cumulative reward per episode was generated, which would visually represent the agent's learning progress (or lack thereof) over the 10,000 training episodes.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The agent did not learn an effective policy to reach the goal in the non-slippery FrozenLake environment based on the evaluation results. This suggests the current hyperparameters or training duration may not be sufficient, or there might be an issue with the Q-learning update logic or state/action representation for this specific environment configuration.\n",
        "*   Next steps should involve debugging the Q-learning implementation, experimenting with different hyperparameters (e.g., higher learning rate, different discount factor, different epsilon decay schedule), increasing the number of training episodes, or potentially using a different reinforcement learning algorithm if Q-learning proves insufficient for this deterministic environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# --- Gym / Gymnasium compatibility ---\n",
        "try:\n",
        "    import gymnasium as gym\n",
        "    from gymnasium.wrappers import TimeLimit\n",
        "except ImportError:\n",
        "    import gym\n",
        "    from gym.wrappers import TimeLimit\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Utility: seed everything for reproducibility\n",
        "# ---------------------------------------------------------\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    try:\n",
        "        import torch\n",
        "        torch.manual_seed(seed)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Q-Learning Agent for Discrete State/Action spaces\n",
        "# ---------------------------------------------------------\n",
        "class QLearningAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_states: int,\n",
        "        n_actions: int,\n",
        "        alpha: float = 0.8,     # learning rate\n",
        "        gamma: float = 0.99,    # discount\n",
        "        epsilon: float = 1.0,   # start exploration\n",
        "        epsilon_min: float = 0.05,\n",
        "        epsilon_decay: float = 0.995\n",
        "    ):\n",
        "        self.n_states = n_states\n",
        "        self.n_actions = n_actions\n",
        "        self.Q = np.zeros((n_states, n_actions), dtype=np.float32)\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "\n",
        "    def policy(self, state: int) -> int:\n",
        "        \"\"\"Epsilon-greedy policy.\"\"\"\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.randint(self.n_actions)\n",
        "        return int(np.argmax(self.Q[state]))\n",
        "\n",
        "    def update(self, s, a, r, s_next, done):\n",
        "        \"\"\"Tabular Q-learning update.\"\"\"\n",
        "        best_next = 0.0 if done else np.max(self.Q[s_next])\n",
        "        td_target = r + self.gamma * best_next\n",
        "        self.Q[s, a] += self.alpha * (td_target - self.Q[s, a])\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Environment helpers (discrete only)\n",
        "# ---------------------------------------------------------\n",
        "def make_env(env_id: str, seed: int = 42, **env_kwargs):\n",
        "    \"\"\"Creates a gym/gymnasium env with a TimeLimit if needed.\"\"\"\n",
        "    env = gym.make(env_id, **env_kwargs)\n",
        "    # Newer Gymnasium uses env.reset(seed=...), Gym classic has env.seed\n",
        "    try:\n",
        "        env.reset(seed=seed)\n",
        "    except TypeError:\n",
        "        try:\n",
        "            env.seed(seed)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Wrap with TimeLimit if not present\n",
        "    has_timelimit = isinstance(env, TimeLimit) or any(\n",
        "        isinstance(w, TimeLimit) for w in getattr(env, \"env\", []).__class__.__mro__\n",
        "    )\n",
        "    if not has_timelimit:\n",
        "        # sensible caps\n",
        "        default_caps = {\n",
        "            \"FrozenLake-v1\": 100,\n",
        "            \"Taxi-v3\": 200,\n",
        "        }\n",
        "        max_steps = default_caps.get(env_id, 200)\n",
        "        env = TimeLimit(env, max_episode_steps=max_steps)\n",
        "\n",
        "    # infer sizes\n",
        "    n_actions = env.action_space.n\n",
        "    # Gymnasium often exposes observation_space.n; discrete assumed.\n",
        "    try:\n",
        "        n_states = env.observation_space.n\n",
        "    except AttributeError:\n",
        "        # Some wrappers may hide .n; try to probe\n",
        "        # For classic discrete envs this should not trigger.\n",
        "        raise ValueError(\"This template expects a discrete observation space with .n\")\n",
        "    return env, n_states, n_actions\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# State representation helpers (for insight/interpretation)\n",
        "# ---------------------------------------------------------\n",
        "def frozenlake_coords(state: int, desc_rows: int, desc_cols: int):\n",
        "    \"\"\"Map a FrozenLake state index to (row, col).\"\"\"\n",
        "    r = state // desc_cols\n",
        "    c = state % desc_cols\n",
        "    return (int(r), int(c))\n",
        "\n",
        "def taxi_decode_state(state: int):\n",
        "    \"\"\"\n",
        "    Decode Taxi-v3's integer state into (taxi_row, taxi_col, passenger_loc, destination).\n",
        "    From Taxi's source: 500 states = 25 taxi positions * 5 passenger locations * 4 destinations.\n",
        "    \"\"\"\n",
        "    # reverse of: state = ((taxi_row * 5 + taxi_col) * 5 + passenger_location) * 4 + destination\n",
        "    dest = state % 4\n",
        "    state //= 4\n",
        "    pass_loc = state % 5\n",
        "    state //= 5\n",
        "    taxi_col = state % 5\n",
        "    state //= 5\n",
        "    taxi_row = state\n",
        "    return int(taxi_row), int(taxi_col), int(pass_loc), int(dest)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Train & evaluate\n",
        "# ---------------------------------------------------------\n",
        "def train_q_learning(\n",
        "    env_id: str,\n",
        "    episodes: int = 5000,\n",
        "    max_steps: int | None = None,\n",
        "    seed: int = 42,\n",
        "    **env_kwargs\n",
        "):\n",
        "    set_seed(seed)\n",
        "    env, n_states, n_actions = make_env(env_id, seed=seed, **env_kwargs)\n",
        "    agent = QLearningAgent(\n",
        "        n_states=n_states,\n",
        "        n_actions=n_actions,\n",
        "        alpha=0.8 if \"FrozenLake\" in env_id else 0.7,\n",
        "        gamma=0.99,\n",
        "        epsilon=1.0,\n",
        "        epsilon_min=0.05,\n",
        "        epsilon_decay=0.997 if \"FrozenLake\" in env_id else 0.995,\n",
        "    )\n",
        "\n",
        "    ep_returns = []\n",
        "    success_flags = []\n",
        "    for ep in range(episodes):\n",
        "        # Gymnasium: reset returns (obs, info); Gym classic: obs\n",
        "        reset_out = env.reset()\n",
        "        if isinstance(reset_out, tuple):\n",
        "            state, _ = reset_out\n",
        "        else:\n",
        "            state = reset_out\n",
        "\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "\n",
        "        steps = 0\n",
        "        while not done:\n",
        "            a = agent.policy(state)\n",
        "            step_out = env.step(a)\n",
        "            if len(step_out) == 5:  # gymnasium: (obs, reward, terminated, truncated, info)\n",
        "                next_state, reward, terminated, truncated, info = step_out\n",
        "                done = terminated or truncated\n",
        "            else:  # gym classic: (obs, reward, done, info)\n",
        "                next_state, reward, done, info = step_out\n",
        "\n",
        "            agent.update(state, a, reward, next_state, done)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            steps += 1\n",
        "            if max_steps and steps >= max_steps:\n",
        "                break\n",
        "\n",
        "        agent.decay_epsilon()\n",
        "        ep_returns.append(total_reward)\n",
        "\n",
        "        # Define \"success\": env-specific\n",
        "        # FrozenLake: reaching goal yields +1; Taxi: reward > 0 when successful dropoff before truncation\n",
        "        success = (total_reward > 0)\n",
        "        success_flags.append(1 if success else 0)\n",
        "\n",
        "        if (ep + 1) % max(1, episodes // 10) == 0:\n",
        "            last100 = np.mean(success_flags[-100:]) if len(success_flags) >= 100 else np.mean(success_flags)\n",
        "            print(f\"[{env_id}] Episode {ep+1}/{episodes} | \"\n",
        "                  f\"avg_return (last 100): {np.mean(ep_returns[-100:]):.3f} | \"\n",
        "                  f\"success_rate (last 100): {last100:.2%} | epsilon: {agent.epsilon:.3f}\")\n",
        "\n",
        "    return agent, ep_returns, success_flags, env\n",
        "\n",
        "def evaluate(agent: QLearningAgent, env, episodes: int = 20, render: bool = False):\n",
        "    returns = []\n",
        "    successes = 0\n",
        "    for ep in range(episodes):\n",
        "        reset_out = env.reset()\n",
        "        state = reset_out[0] if isinstance(reset_out, tuple) else reset_out\n",
        "        done = False\n",
        "        total = 0.0\n",
        "        while not done:\n",
        "            a = int(np.argmax(agent.Q[state]))  # greedy\n",
        "            step_out = env.step(a)\n",
        "            if len(step_out) == 5:\n",
        "                state, reward, terminated, truncated, _ = step_out\n",
        "                done = terminated or truncated\n",
        "            else:\n",
        "                state, reward, done, _ = step_out\n",
        "            total += reward\n",
        "            if render:\n",
        "                try:\n",
        "                    env.render()\n",
        "                except Exception:\n",
        "                    pass\n",
        "        returns.append(total)\n",
        "        if total > 0:\n",
        "            successes += 1\n",
        "    print(f\"Eval over {episodes} episodes -> \"\n",
        "          f\"avg_return: {np.mean(returns):.3f}, success_rate: {successes/episodes:.2%}\")\n",
        "    return returns\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Demo runners\n",
        "# ---------------------------------------------------------\n",
        "def run_frozenlake(slippery=False, episodes=8000):\n",
        "    print(f\"\\n=== Training FrozenLake-v1 (slippery={slippery}) ===\")\n",
        "    # map_name examples: \"4x4\", \"8x8\" (Gymnasium)\n",
        "    agent, ep_returns, success_flags, env = train_q_learning(\n",
        "        \"FrozenLake-v1\",\n",
        "        is_slippery=slippery,\n",
        "        map_name=\"4x4\",\n",
        "        episodes=episodes,\n",
        "        seed=123\n",
        "    )\n",
        "\n",
        "    # Show how to interpret a random state:\n",
        "    try:\n",
        "        desc = env.unwrapped.desc\n",
        "        h, w = desc.shape\n",
        "        example_state = np.random.randint(env.observation_space.n)\n",
        "        print(\"FrozenLake representation example:\",\n",
        "              f\"state={example_state} -> coords={frozenlake_coords(example_state, h, w)} (row, col)\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    evaluate(agent, env, episodes=50)\n",
        "    # quick greedy rollout print\n",
        "    print_sample_rollout(agent, env, decoder=\"frozenlake\")\n",
        "\n",
        "def run_taxi(episodes=5000):\n",
        "    print(\"\\n=== Training Taxi-v3 ===\")\n",
        "    agent, ep_returns, success_flags, env = train_q_learning(\n",
        "        \"Taxi-v3\",\n",
        "        episodes=episodes,\n",
        "        seed=7\n",
        "    )\n",
        "\n",
        "    # Decode a random state to a meaningful tuple\n",
        "    sample_state = np.random.randint(env.observation_space.n)\n",
        "    print(\"Taxi representation example:\",\n",
        "          f\"state={sample_state} -> (row, col, passenger_loc, destination)={taxi_decode_state(sample_state)}\")\n",
        "\n",
        "    evaluate(agent, env, episodes=50)\n",
        "    # quick greedy rollout print\n",
        "    print_sample_rollout(agent, env, decoder=\"taxi\")\n",
        "\n",
        "def print_sample_rollout(agent, env, max_steps=40, decoder=\"none\"):\n",
        "    print(\"\\n--- Greedy rollout (sample) ---\")\n",
        "    reset_out = env.reset()\n",
        "    state = reset_out[0] if isinstance(reset_out, tuple) else reset_out\n",
        "    total = 0.0\n",
        "    for t in range(max_steps):\n",
        "        a = int(np.argmax(agent.Q[state]))\n",
        "        step_out = env.step(a)\n",
        "        if len(step_out) == 5:\n",
        "            next_state, reward, terminated, truncated, info = step_out\n",
        "            done = terminated or truncated\n",
        "        else:\n",
        "            next_state, reward, done, info = step_out\n",
        "\n",
        "        # Human-readable state\n",
        "        if decoder == \"frozenlake\":\n",
        "            try:\n",
        "                desc = env.unwrapped.desc\n",
        "                h, w = desc.shape\n",
        "                coords = frozenlake_coords(state, h, w)\n",
        "                print(f\"t={t:02d} state={state:2d} (r,c)={coords} action={a} reward={reward}\")\n",
        "            except Exception:\n",
        "                print(f\"t={t:02d} state={state:2d} action={a} reward={reward}\")\n",
        "        elif decoder == \"taxi\":\n",
        "            print(f\"t={t:02d} state={state:3d} dec={taxi_decode_state(state)} action={a} reward={reward}\")\n",
        "        else:\n",
        "            print(f\"t={t:02d} state={state} action={a} reward={reward}\")\n",
        "\n",
        "        total += reward\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "    print(f\"Total reward in rollout: {total}\\n\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Main: choose which demo(s) to run\n",
        "# ---------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Train FrozenLake deterministic (easier) and slippery (harder)\n",
        "    run_frozenlake(slippery=False, episodes=6000)   # try 6k–12k for 4x4\n",
        "    run_frozenlake(slippery=True,  episodes=12000)  # slippery needs more episodes\n",
        "    # Train Taxi\n",
        "    run_taxi(episodes=6000)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDlrpt336lwt",
        "outputId": "68d49f60-ac15-48a9-c73b-4fbbfb94e42c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training FrozenLake-v1 (slippery=False) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FrozenLake-v1] Episode 600/6000 | avg_return (last 100): 0.840 | success_rate (last 100): 84.00% | epsilon: 0.165\n",
            "[FrozenLake-v1] Episode 1200/6000 | avg_return (last 100): 0.980 | success_rate (last 100): 98.00% | epsilon: 0.050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FrozenLake-v1] Episode 1800/6000 | avg_return (last 100): 0.940 | success_rate (last 100): 94.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 2400/6000 | avg_return (last 100): 0.950 | success_rate (last 100): 95.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 3000/6000 | avg_return (last 100): 0.910 | success_rate (last 100): 91.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 3600/6000 | avg_return (last 100): 0.940 | success_rate (last 100): 94.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 4200/6000 | avg_return (last 100): 0.920 | success_rate (last 100): 92.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 4800/6000 | avg_return (last 100): 0.970 | success_rate (last 100): 97.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 5400/6000 | avg_return (last 100): 0.950 | success_rate (last 100): 95.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 6000/6000 | avg_return (last 100): 0.910 | success_rate (last 100): 91.00% | epsilon: 0.050\n",
            "FrozenLake representation example: state=10 -> coords=(2, 2) (row, col)\n",
            "Eval over 50 episodes -> avg_return: 1.000, success_rate: 100.00%\n",
            "\n",
            "--- Greedy rollout (sample) ---\n",
            "t=00 state= 0 (r,c)=(0, 0) action=1 reward=0.0\n",
            "t=01 state= 4 (r,c)=(1, 0) action=1 reward=0.0\n",
            "t=02 state= 8 (r,c)=(2, 0) action=2 reward=0.0\n",
            "t=03 state= 9 (r,c)=(2, 1) action=1 reward=0.0\n",
            "t=04 state=13 (r,c)=(3, 1) action=2 reward=0.0\n",
            "t=05 state=14 (r,c)=(3, 2) action=2 reward=1.0\n",
            "Total reward in rollout: 1.0\n",
            "\n",
            "\n",
            "=== Training FrozenLake-v1 (slippery=True) ===\n",
            "[FrozenLake-v1] Episode 1200/12000 | avg_return (last 100): 0.230 | success_rate (last 100): 23.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 2400/12000 | avg_return (last 100): 0.230 | success_rate (last 100): 23.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 3600/12000 | avg_return (last 100): 0.270 | success_rate (last 100): 27.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 4800/12000 | avg_return (last 100): 0.270 | success_rate (last 100): 27.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 6000/12000 | avg_return (last 100): 0.330 | success_rate (last 100): 33.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 7200/12000 | avg_return (last 100): 0.260 | success_rate (last 100): 26.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 8400/12000 | avg_return (last 100): 0.210 | success_rate (last 100): 21.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 9600/12000 | avg_return (last 100): 0.180 | success_rate (last 100): 18.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 10800/12000 | avg_return (last 100): 0.330 | success_rate (last 100): 33.00% | epsilon: 0.050\n",
            "[FrozenLake-v1] Episode 12000/12000 | avg_return (last 100): 0.250 | success_rate (last 100): 25.00% | epsilon: 0.050\n",
            "FrozenLake representation example: state=6 -> coords=(1, 2) (row, col)\n",
            "Eval over 50 episodes -> avg_return: 0.560, success_rate: 56.00%\n",
            "\n",
            "--- Greedy rollout (sample) ---\n",
            "t=00 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=01 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=02 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=03 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=04 state= 9 (r,c)=(2, 1) action=1 reward=0.0\n",
            "t=05 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=06 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=07 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=08 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=09 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=10 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=11 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=12 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=13 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=14 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=15 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=16 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=17 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=18 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=19 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=20 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=21 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=22 state= 0 (r,c)=(0, 0) action=0 reward=0.0\n",
            "t=23 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=24 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=25 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=26 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=27 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=28 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=29 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=30 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=31 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=32 state= 4 (r,c)=(1, 0) action=0 reward=0.0\n",
            "t=33 state= 8 (r,c)=(2, 0) action=3 reward=0.0\n",
            "t=34 state= 9 (r,c)=(2, 1) action=1 reward=0.0\n",
            "t=35 state=13 (r,c)=(3, 1) action=2 reward=0.0\n",
            "t=36 state=14 (r,c)=(3, 2) action=3 reward=0.0\n",
            "t=37 state=10 (r,c)=(2, 2) action=0 reward=0.0\n",
            "t=38 state= 9 (r,c)=(2, 1) action=1 reward=0.0\n",
            "t=39 state=10 (r,c)=(2, 2) action=0 reward=0.0\n",
            "Total reward in rollout: 0.0\n",
            "\n",
            "\n",
            "=== Training Taxi-v3 ===\n",
            "[Taxi-v3] Episode 600/6000 | avg_return (last 100): 3.390 | success_rate (last 100): 74.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 1200/6000 | avg_return (last 100): 4.030 | success_rate (last 100): 80.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 1800/6000 | avg_return (last 100): 4.780 | success_rate (last 100): 85.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 2400/6000 | avg_return (last 100): 5.510 | success_rate (last 100): 87.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 3000/6000 | avg_return (last 100): 6.510 | success_rate (last 100): 91.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 3600/6000 | avg_return (last 100): 4.860 | success_rate (last 100): 79.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 4200/6000 | avg_return (last 100): 4.170 | success_rate (last 100): 81.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 4800/6000 | avg_return (last 100): 5.630 | success_rate (last 100): 85.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 5400/6000 | avg_return (last 100): 4.600 | success_rate (last 100): 80.00% | epsilon: 0.050\n",
            "[Taxi-v3] Episode 6000/6000 | avg_return (last 100): 4.650 | success_rate (last 100): 85.00% | epsilon: 0.050\n",
            "Taxi representation example: state=384 -> (row, col, passenger_loc, destination)=(3, 4, 1, 0)\n",
            "Eval over 50 episodes -> avg_return: 7.700, success_rate: 100.00%\n",
            "\n",
            "--- Greedy rollout (sample) ---\n",
            "t=00 state=414 dec=(4, 0, 3, 2) action=1 reward=-1\n",
            "t=01 state=314 dec=(3, 0, 3, 2) action=1 reward=-1\n",
            "t=02 state=214 dec=(2, 0, 3, 2) action=2 reward=-1\n",
            "t=03 state=234 dec=(2, 1, 3, 2) action=2 reward=-1\n",
            "t=04 state=254 dec=(2, 2, 3, 2) action=2 reward=-1\n",
            "t=05 state=274 dec=(2, 3, 3, 2) action=0 reward=-1\n",
            "t=06 state=374 dec=(3, 3, 3, 2) action=0 reward=-1\n",
            "t=07 state=474 dec=(4, 3, 3, 2) action=4 reward=-1\n",
            "t=08 state=478 dec=(4, 3, 4, 2) action=1 reward=-1\n",
            "t=09 state=378 dec=(3, 3, 4, 2) action=1 reward=-1\n",
            "t=10 state=278 dec=(2, 3, 4, 2) action=3 reward=-1\n",
            "t=11 state=258 dec=(2, 2, 4, 2) action=3 reward=-1\n",
            "t=12 state=238 dec=(2, 1, 4, 2) action=3 reward=-1\n",
            "t=13 state=218 dec=(2, 0, 4, 2) action=0 reward=-1\n",
            "t=14 state=318 dec=(3, 0, 4, 2) action=0 reward=-1\n",
            "t=15 state=418 dec=(4, 0, 4, 2) action=5 reward=20\n",
            "Total reward in rollout: 5.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "488172c4",
        "outputId": "58255501-76de-4513-85e4-f85eccf042b2"
      },
      "source": [
        "# Plot the cumulative reward per episode\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(cumulative_rewards)\n",
        "plt.title(\"Q-learning Training Progress: Cumulative Reward per Episode\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Cumulative Reward\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Brief analysis\n",
        "# The plot shows the cumulative reward obtained in each episode during training.\n",
        "# Observing the trend can indicate whether the agent is learning effectively.\n",
        "# An upward trend would suggest learning progress, while plateaus or fluctuations might indicate slower learning or challenges in the environment."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}