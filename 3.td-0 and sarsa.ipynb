{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQkTVbXrV3U+uRe7AgnM0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarriRohan/Reinforcement-Learning-2025/blob/main/3.td-0%20and%20sarsa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80c93bee",
        "outputId": "d2ab3d77-587a-4c9c-dbf4-c0781e4b88eb"
      },
      "source": [
        "# 8. Evaluate the performance of both algorithms.\n",
        "\n",
        "print(\"--- TD-0 Learned Value Function ---\")\n",
        "# Sort states for consistent output\n",
        "sorted_states_td0 = sorted(learned_values_td0.keys())\n",
        "for state in sorted_states_td0:\n",
        "    value = learned_values_td0[state]\n",
        "    print(f\"State: {state}, Value: {value:.4f}\")\n",
        "\n",
        "print(\"\\n--- SARSA Learned Q-table ---\")\n",
        "# Sort states for consistent output\n",
        "sorted_states_sarsa = sorted(learned_q_table_sarsa.keys())\n",
        "for state in sorted_states_sarsa:\n",
        "    q_values = learned_q_table_sarsa[state]\n",
        "    print(f\"State: {state}, Q-values: {q_values}\")\n",
        "\n",
        "print(\"\\n--- SARSA Derived Optimal Policy ---\")\n",
        "optimal_policy_sarsa = {}\n",
        "for state, q_values in learned_q_table_sarsa.items():\n",
        "    if state != goal_state and state not in obstacles:\n",
        "        # Choose the action with the maximum Q-value\n",
        "        optimal_action = max(q_values, key=q_values.get)\n",
        "        optimal_policy_sarsa[state] = optimal_action\n",
        "\n",
        "# Sort states for consistent output\n",
        "sorted_states_policy = sorted(optimal_policy_sarsa.keys())\n",
        "for state in sorted_states_policy:\n",
        "    action = optimal_policy_sarsa[state]\n",
        "    print(f\"State: {state}, Optimal Action: {action}\")\n",
        "\n",
        "# Optional: Simulate an agent following the optimal SARSA policy\n",
        "print(\"\\n--- Simulating SARSA Optimal Policy ---\")\n",
        "current_state = start_state\n",
        "path = [current_state]\n",
        "total_reward = 0\n",
        "steps = 0\n",
        "max_steps = 100 # Prevent infinite loops\n",
        "\n",
        "while current_state != goal_state and steps < max_steps:\n",
        "    if current_state in optimal_policy_sarsa:\n",
        "        action = optimal_policy_sarsa[current_state]\n",
        "        next_state, reward = env.get_next_state_and_reward(current_state, action)\n",
        "        total_reward += reward\n",
        "        current_state = next_state\n",
        "        path.append(current_state)\n",
        "        steps += 1\n",
        "    else:\n",
        "        # Handle states not in the policy (should primarily be goal/obstacles)\n",
        "        break\n",
        "\n",
        "print(f\"Simulation Path: {path}\")\n",
        "print(f\"Total Reward: {total_reward}\")\n",
        "print(f\"Steps taken: {steps}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TD-0 Learned Value Function ---\n",
            "State: (0, 0), Value: 4.7830\n",
            "State: (0, 1), Value: 5.3144\n",
            "State: (0, 2), Value: 5.9049\n",
            "State: (0, 3), Value: 6.5610\n",
            "State: (0, 4), Value: 7.2900\n",
            "State: (1, 0), Value: 0.0000\n",
            "State: (1, 1), Value: 0.0000\n",
            "State: (1, 2), Value: 0.0000\n",
            "State: (1, 3), Value: 0.0000\n",
            "State: (1, 4), Value: 8.1000\n",
            "State: (2, 0), Value: 0.0000\n",
            "State: (2, 1), Value: 0.0000\n",
            "State: (2, 2), Value: 0.0000\n",
            "State: (2, 3), Value: 0.0000\n",
            "State: (2, 4), Value: 9.0000\n",
            "State: (3, 0), Value: 0.0000\n",
            "State: (3, 1), Value: 0.0000\n",
            "State: (3, 2), Value: 0.0000\n",
            "State: (3, 3), Value: 0.0000\n",
            "State: (3, 4), Value: 10.0000\n",
            "State: (4, 0), Value: 0.0000\n",
            "State: (4, 1), Value: 0.0000\n",
            "State: (4, 2), Value: 0.0000\n",
            "State: (4, 3), Value: 0.0000\n",
            "State: (4, 4), Value: 0.0000\n",
            "\n",
            "--- SARSA Learned Q-table ---\n",
            "State: (0, 0), Q-values: {'up': 2.7926726789033, 'down': 3.0396437188551113, 'left': 2.7230106323411603, 'right': 4.260908114897418}\n",
            "State: (0, 1), Q-values: {'up': 3.190329772061495, 'down': 3.0837091125279423, 'left': 3.626721761063476, 'right': 4.850883611659155}\n",
            "State: (0, 2), Q-values: {'up': 3.781459863582482, 'down': 3.835060810213672, 'left': 4.069783069244354, 'right': 5.463685858086552}\n",
            "State: (0, 3), Q-values: {'up': 4.48624932822958, 'down': 6.068106177229673, 'left': 4.5215739014911325, 'right': 5.742489735812782}\n",
            "State: (0, 4), Q-values: {'up': 3.2011925899537874, 'down': 6.926196211606516, 'left': 4.400962450176014, 'right': 4.153882225778488}\n",
            "State: (1, 0), Q-values: {'up': 3.7915401161736506, 'down': -0.07691582824682089, 'left': 0.22042741297737772, 'right': -0.6385766068159306}\n",
            "State: (1, 3), Q-values: {'up': 5.38920895180225, 'down': 6.476411693153854, 'left': 5.221392199642803, 'right': 6.8840158037778965}\n",
            "State: (1, 4), Q-values: {'up': 5.955703953780955, 'down': 7.735676616470966, 'left': 6.010838362134286, 'right': 6.008469687731319}\n",
            "State: (2, 0), Q-values: {'up': -0.08172216353386147, 'down': -0.0835615180602158, 'left': -0.5846694233763781, 'right': 0.03051943177297203}\n",
            "State: (2, 1), Q-values: {'up': -0.5744064400952632, 'down': 0.30145676693719836, 'left': -0.06428053254286535, 'right': -0.40737338921005006}\n",
            "State: (2, 3), Q-values: {'up': 3.097200659112747, 'down': 2.3469898427086537, 'left': 3.643471720519107, 'right': 7.853747101277577}\n",
            "State: (2, 4), Q-values: {'up': 6.800515364239154, 'down': 8.678216889417914, 'left': 6.853728934395548, 'right': 6.781458684551652}\n",
            "State: (3, 0), Q-values: {'up': -0.07767715153133947, 'down': 0.038006397611076874, 'left': -0.6613196459809403, 'right': -0.06788280376653381}\n",
            "State: (3, 1), Q-values: {'up': -0.07172350853287142, 'down': 1.523080868760926, 'left': -0.07393576731388639, 'right': -0.39392977375473903}\n",
            "State: (3, 4), Q-values: {'up': 7.7736190966625704, 'down': 9.999999999999993, 'left': 7.783171051147876, 'right': 7.7398504846163565}\n",
            "State: (4, 0), Q-values: {'up': -0.08118641291251677, 'down': -0.34718993624002276, 'left': -0.4098403567999579, 'right': 0.517193889661529}\n",
            "State: (4, 1), Q-values: {'up': 0.07591775991029893, 'down': -0.5284216644401764, 'left': -0.05204769420969188, 'right': 3.9431240662885014}\n",
            "State: (4, 2), Q-values: {'up': -0.43148056162412207, 'down': -0.19, 'left': -0.014954274706283133, 'right': 6.730078352717132}\n",
            "State: (4, 3), Q-values: {'up': -0.1, 'down': -0.181, 'left': -0.009000000000000001, 'right': 9.353891811077332}\n",
            "State: (4, 4), Q-values: {'up': 0.0, 'down': 0.0, 'left': 0.0, 'right': 0.0}\n",
            "\n",
            "--- SARSA Derived Optimal Policy ---\n",
            "State: (0, 0), Optimal Action: right\n",
            "State: (0, 1), Optimal Action: right\n",
            "State: (0, 2), Optimal Action: right\n",
            "State: (0, 3), Optimal Action: down\n",
            "State: (0, 4), Optimal Action: down\n",
            "State: (1, 0), Optimal Action: up\n",
            "State: (1, 3), Optimal Action: right\n",
            "State: (1, 4), Optimal Action: down\n",
            "State: (2, 0), Optimal Action: right\n",
            "State: (2, 1), Optimal Action: down\n",
            "State: (2, 3), Optimal Action: right\n",
            "State: (2, 4), Optimal Action: down\n",
            "State: (3, 0), Optimal Action: down\n",
            "State: (3, 1), Optimal Action: down\n",
            "State: (3, 4), Optimal Action: down\n",
            "State: (4, 0), Optimal Action: right\n",
            "State: (4, 1), Optimal Action: right\n",
            "State: (4, 2), Optimal Action: right\n",
            "State: (4, 3), Optimal Action: right\n",
            "\n",
            "--- Simulating SARSA Optimal Policy ---\n",
            "Simulation Path: [(0, 0), (0, 1), (0, 2), (0, 3), (1, 3), (1, 4), (2, 4), (3, 4), (4, 4)]\n",
            "Total Reward: 10\n",
            "Steps taken: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0a7c9a7"
      },
      "source": [
        "# 6. Define the parameters for the SARSA algorithm\n",
        "alpha_sarsa = 0.1\n",
        "gamma_sarsa = 0.9\n",
        "epsilon_sarsa = 0.1\n",
        "num_episodes_sarsa = 5000\n",
        "\n",
        "# 7. Run the sarsa function\n",
        "learned_q_table_sarsa = sarsa(env, alpha_sarsa, gamma_sarsa, epsilon_sarsa, num_episodes_sarsa)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3d2e67e"
      },
      "source": [
        "# 3. Define the parameters for the TD-0 algorithm\n",
        "gamma_td0 = 0.9\n",
        "alpha_td0 = 0.1\n",
        "num_episodes_td0 = 1000\n",
        "\n",
        "# 4. Define a fixed policy for the TD-0 algorithm.\n",
        "# This policy should cover all non-terminal, non-obstacle states.\n",
        "# A simple policy like trying to move right if possible, otherwise down, could be used.\n",
        "fixed_policy = {}\n",
        "for r in range(rows):\n",
        "    for c in range(cols):\n",
        "        state = (r, c)\n",
        "        if state not in obstacles and state != goal_state:\n",
        "            # Simple policy: try to move right, if blocked, move down\n",
        "            next_state_right, _ = env.get_next_state_and_reward(state, 'right')\n",
        "            if next_state_right != state: # Check if moving right is possible\n",
        "                fixed_policy[state] = 'right'\n",
        "            else:\n",
        "                fixed_policy[state] = 'down' # Default to down if right is blocked\n",
        "\n",
        "# Ensure the policy doesn't include goal or obstacle states (redundant check but safe)\n",
        "for state in list(fixed_policy.keys()):\n",
        "     if state in obstacles or state == goal_state:\n",
        "         del fixed_policy[state]\n",
        "\n",
        "# 5. Run the td_zero_policy_evaluation function\n",
        "learned_values_td0 = td_zero_policy_evaluation(env, fixed_policy, gamma_td0, alpha_td0, num_episodes_td0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b89164f"
      },
      "source": [
        "# 1. Define the grid world parameters\n",
        "rows = 5\n",
        "cols = 5\n",
        "start_state = (0, 0)\n",
        "goal_state = (4, 4)\n",
        "obstacles = [(1, 1), (1, 2), (2, 2), (3, 2), (3, 3)]\n",
        "\n",
        "# 2. Create an instance of the GridWorld environment\n",
        "env = GridWorld(rows, cols, start_state, goal_state, obstacles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "782eb6de"
      },
      "source": [
        "import random\n",
        "\n",
        "def sarsa(env, alpha, gamma, epsilon, num_episodes):\n",
        "    \"\"\"\n",
        "    Implements the SARSA algorithm for learning an optimal policy and value function.\n",
        "\n",
        "    Args:\n",
        "        env: The GridWorld environment instance.\n",
        "        alpha: The learning rate.\n",
        "        gamma: The discount factor.\n",
        "        epsilon: The exploration rate for epsilon-greedy policy.\n",
        "        num_episodes: The number of episodes to run.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary representing the learned Q-table.\n",
        "    \"\"\"\n",
        "    # Initialize Q-table\n",
        "    Q = {}\n",
        "    for r in range(env.rows):\n",
        "        for c in range(env.cols):\n",
        "            state = (r, c)\n",
        "            if state not in env.obstacles: # Q-values for obstacle states are not needed\n",
        "                 Q[state] = {action: 0.0 for action in env.actions.keys()}\n",
        "\n",
        "\n",
        "    def epsilon_greedy_policy(state, Q, epsilon):\n",
        "        \"\"\"\n",
        "        Selects an action using an epsilon-greedy policy.\n",
        "        \"\"\"\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            # Explore: choose a random action\n",
        "            return random.choice(list(env.actions.keys()))\n",
        "        else:\n",
        "            # Exploit: choose the action with the highest Q-value for the current state\n",
        "            if state in Q:\n",
        "                return max(Q[state], key=Q[state].get)\n",
        "            else:\n",
        "                # If state is not in Q (e.g., goal state), return a default action or handle appropriately\n",
        "                # For this grid world, goal state is terminal so this case shouldn't be reached in action selection for update\n",
        "                return random.choice(list(env.actions.keys())) # Should not happen for states in Q\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        current_state = env.start_state\n",
        "        # Select the first action using the epsilon-greedy policy\n",
        "        current_action = epsilon_greedy_policy(current_state, Q, epsilon)\n",
        "\n",
        "        while current_state != env.goal_state:\n",
        "            # Take the selected action\n",
        "            next_state, reward = env.get_next_state_and_reward(current_state, current_action)\n",
        "\n",
        "            # Select the next action from the next state using the epsilon-greedy policy\n",
        "            next_action = epsilon_greedy_policy(next_state, Q, epsilon)\n",
        "\n",
        "            # SARSA update rule\n",
        "            if current_state in Q and current_action in Q[current_state]:\n",
        "                # Handle the case where next_state is the goal state (terminal)\n",
        "                if next_state == env.goal_state:\n",
        "                     Q_next = 0.0 # Value of terminal state is 0\n",
        "                elif next_state in Q and next_action in Q[next_state]:\n",
        "                     Q_next = Q[next_state][next_action]\n",
        "                else:\n",
        "                    # This case might occur if the next_state is an obstacle,\n",
        "                    # although get_next_state_and_reward should prevent moving into one.\n",
        "                    # If it somehow happens, treat Q_next as 0 or handle as an error.\n",
        "                    # Based on GridWorld implementation, moving into obstacle results in staying put with penalty,\n",
        "                    # so next_state should be in Q unless it's the goal.\n",
        "                    Q_next = 0.0\n",
        "\n",
        "\n",
        "                Q[current_state][current_action] = Q[current_state][current_action] + alpha * (reward + gamma * Q_next - Q[current_state][current_action])\n",
        "\n",
        "            # Update current state and current action\n",
        "            current_state = next_state\n",
        "            current_action = next_action\n",
        "\n",
        "    return Q\n",
        "\n",
        "# Example Usage (optional, for testing)\n",
        "# rows = 5\n",
        "# cols = 5\n",
        "# start = (0, 0)\n",
        "# goal = (4, 4)\n",
        "# obstacles = [(1, 1), (1, 2), (2, 2), (3, 2), (3, 3)]\n",
        "#\n",
        "# env = GridWorld(rows, cols, start, goal, obstacles)\n",
        "#\n",
        "# alpha = 0.1\n",
        "# gamma = 0.9\n",
        "# epsilon = 0.1\n",
        "# num_episodes = 5000\n",
        "#\n",
        "# learned_q_table = sarsa(env, alpha, gamma, epsilon, num_episodes)\n",
        "#\n",
        "# print(\"Learned Q-table:\")\n",
        "# for state, actions in learned_q_table.items():\n",
        "#     print(f\"State: {state}, Q-values: {actions}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bda3069f"
      },
      "source": [
        "def td_zero_policy_evaluation(env, policy, gamma, alpha, num_episodes):\n",
        "    \"\"\"\n",
        "    Performs TD-0 policy evaluation for a given policy in a GridWorld environment.\n",
        "\n",
        "    Args:\n",
        "        env: The GridWorld environment instance.\n",
        "        policy: A dictionary mapping states to actions (fixed policy).\n",
        "        gamma: The discount factor.\n",
        "        alpha: The learning rate.\n",
        "        num_episodes: The number of episodes to run.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary or NumPy array representing the learned value function V.\n",
        "    \"\"\"\n",
        "    # Initialize value function\n",
        "    V = {}\n",
        "    for r in range(env.rows):\n",
        "        for c in range(env.cols):\n",
        "            state = (r, c)\n",
        "            if state not in env.obstacles and state != env.goal_state:\n",
        "                V[state] = 0.0\n",
        "            elif state == env.goal_state:\n",
        "                 V[state] = 0.0 # Goal state value is typically 0 in value iteration, but can be non-zero in TD\n",
        "            else:\n",
        "                 V[state] = 0.0 # Obstacle states typically have no value\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        current_state = env.start_state\n",
        "\n",
        "        while current_state != env.goal_state:\n",
        "            if current_state in policy:\n",
        "                action = policy[current_state]\n",
        "            else:\n",
        "                # Handle states not in policy, e.g., obstacles or goal state\n",
        "                # For this implementation, we assume the policy covers all non-terminal, non-obstacle states.\n",
        "                # If the current_state is an obstacle or goal, the loop condition will handle it.\n",
        "                break # Exit if the current state is not in the policy (e.g., goal or obstacle)\n",
        "\n",
        "            next_state, reward = env.get_next_state_and_reward(current_state, action)\n",
        "\n",
        "            # TD-0 update rule\n",
        "            if next_state in V: # Ensure next_state is in the value function dictionary\n",
        "                 V[current_state] = V[current_state] + alpha * (reward + gamma * V[next_state] - V[current_state])\n",
        "            else:\n",
        "                 # If next_state is a terminal state (like goal), its value is implicitly 0 for the update\n",
        "                 V[current_state] = V[current_state] + alpha * (reward + gamma * 0 - V[current_state])\n",
        "\n",
        "\n",
        "            current_state = next_state\n",
        "\n",
        "    return V\n",
        "\n",
        "# Example Usage (optional, for testing)\n",
        "# rows = 5\n",
        "# cols = 5\n",
        "# start = (0, 0)\n",
        "# goal = (4, 4)\n",
        "# obstacles = [(1, 1), (1, 2), (2, 2), (3, 2), (3, 3)]\n",
        "#\n",
        "# env = GridWorld(rows, cols, start, goal, obstacles)\n",
        "#\n",
        "# # Example fixed policy (move right if possible, otherwise down)\n",
        "# fixed_policy = {}\n",
        "# for r in range(rows):\n",
        "#     for c in range(cols):\n",
        "#         state = (r, c)\n",
        "#         if state not in obstacles and state != goal:\n",
        "#             # Simple policy: try to move right, if blocked, move down\n",
        "#             next_state_right, _ = env.get_next_state_and_reward(state, 'right')\n",
        "#             if next_state_right != state: # Check if moving right is possible\n",
        "#                 fixed_policy[state] = 'right'\n",
        "#             else:\n",
        "#                 fixed_policy[state] = 'down' # Default to down if right is blocked\n",
        "#\n",
        "# # Ensure the policy doesn't include goal or obstacle states\n",
        "# for state in list(fixed_policy.keys()):\n",
        "#      if state in obstacles or state == goal:\n",
        "#          del fixed_policy[state]\n",
        "#\n",
        "# gamma = 0.9\n",
        "# alpha = 0.1\n",
        "# num_episodes = 1000\n",
        "#\n",
        "# learned_values = td_zero_policy_evaluation(env, fixed_policy, gamma, alpha, num_episodes)\n",
        "#\n",
        "# print(\"Learned Value Function:\")\n",
        "# for state, value in learned_values.items():\n",
        "#     print(f\"State: {state}, Value: {value:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c105774"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class GridWorld:\n",
        "    def __init__(self, rows, cols, start_state, goal_state, obstacles):\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.start_state = start_state\n",
        "        self.goal_state = goal_state\n",
        "        self.obstacles = obstacles\n",
        "        self.grid = np.zeros((rows, cols))\n",
        "        self._initialize_grid()\n",
        "\n",
        "        self.actions = {'up': (-1, 0), 'down': (1, 0), 'left': (0, -1), 'right': (0, 1)}\n",
        "\n",
        "    def _initialize_grid(self):\n",
        "        for r, c in self.obstacles:\n",
        "            self.grid[r, c] = -1  # Represent obstacles with -1\n",
        "        self.grid[self.goal_state] = 1  # Represent goal with 1\n",
        "\n",
        "    def get_next_state_and_reward(self, state, action):\n",
        "        if action not in self.actions:\n",
        "            return state, -1 # Invalid action penalty\n",
        "\n",
        "        dr, dc = self.actions[action]\n",
        "        next_state = (state[0] + dr, state[1] + dc)\n",
        "\n",
        "        # Check boundary conditions\n",
        "        if not (0 <= next_state[0] < self.rows and 0 <= next_state[1] < self.cols):\n",
        "            return state, -1  # Stay in the current state and penalize\n",
        "\n",
        "        # Check for obstacles\n",
        "        if next_state in self.obstacles:\n",
        "            return state, -1  # Stay in the current state and penalize\n",
        "\n",
        "        # Check for goal state\n",
        "        if next_state == self.goal_state:\n",
        "            return next_state, 10  # Reach goal and get reward\n",
        "\n",
        "        # Normal transition\n",
        "        return next_state, 0\n",
        "\n",
        "# Example Usage (optional, for testing)\n",
        "# rows = 5\n",
        "# cols = 5\n",
        "# start = (0, 0)\n",
        "# goal = (4, 4)\n",
        "# obstacles = [(1, 1), (1, 2), (2, 2), (3, 2), (3, 3)]\n",
        "#\n",
        "# env = GridWorld(rows, cols, start, goal, obstacles)\n",
        "#\n",
        "# current_state = start\n",
        "# action = 'right'\n",
        "# next_state, reward = env.get_next_state_and_reward(current_state, action)\n",
        "# print(f\"Current state: {current_state}, Action: {action}, Next state: {next_state}, Reward: {reward}\")\n",
        "#\n",
        "# current_state = (0, 4)\n",
        "# action = 'down'\n",
        "# next_state, reward = env.get_next_state_and_reward(current_state, action)\n",
        "# print(f\"Current state: {current_state}, Action: {action}, Next state: {next_state}, Reward: {reward}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d494287f"
      },
      "source": [
        "# Task\n",
        "Implement the TD-0 and SARSA algorithms for a grid world environment in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f06363aa"
      },
      "source": [
        "## Define the grid world environment\n",
        "\n",
        "### Subtask:\n",
        "Create a class or functions to represent the grid world, including states, actions, transitions, and rewards.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ec6bb74"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a class to represent the grid world with its dimensions, special states, actions, and a function for state transitions and rewards.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f645ea1"
      },
      "source": [
        "## Implement td-0 algorithm\n",
        "\n",
        "### Subtask:\n",
        "Create a function or class to implement the TD-0 algorithm for policy evaluation, given a fixed policy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b234a2e"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the `td_zero_policy_evaluation` function as described in the instructions, including initializing the value function, iterating through episodes, and updating the value function using the TD-0 rule.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf3b2830"
      },
      "source": [
        "## Implement sarsa algorithm\n",
        "\n",
        "### Subtask:\n",
        "Create a function or class to implement the SARSA algorithm for learning an optimal policy and value function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c5f1e1f"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `sarsa` function, initialize the Q-table, implement the epsilon-greedy policy, and iterate through episodes to perform the SARSA updates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f09826b"
      },
      "source": [
        "## Simulate and evaluate\n",
        "\n",
        "### Subtask:\n",
        "Run simulations of the agents using both TD-0 and SARSA in the grid world and evaluate their performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ac24f6b"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the grid world parameters and create an instance of the GridWorld environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75592d84"
      },
      "source": [
        "**Reasoning**:\n",
        "Define parameters for the TD-0 algorithm, define a fixed policy, and run the TD-0 policy evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6176afe"
      },
      "source": [
        "**Reasoning**:\n",
        "Define parameters for the SARSA algorithm and run the SARSA algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6fdcf14"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the performance of both algorithms by analyzing the learned value function for TD-0 and the learned Q-table for SARSA. For SARSA, also derive and print the optimal policy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75cd8d4"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The TD-0 algorithm was successfully implemented and used to evaluate a fixed policy in the grid world, producing a value function that reflects the expected cumulative reward from each state under that policy.\n",
        "*   The SARSA algorithm was successfully implemented and used to learn a Q-table for the grid world environment, representing the estimated value of taking each action in each state.\n",
        "*   An optimal policy was successfully derived from the learned SARSA Q-table, indicating the best action to take in each state to maximize future reward.\n",
        "*   A simulation using the derived SARSA optimal policy demonstrated the agent successfully navigating the grid world, avoiding obstacles, and reaching the goal state.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Comparing the values learned by TD-0 under the fixed policy with the values derived from the SARSA Q-table under its optimal policy could provide insights into the difference in performance between the fixed policy and the learned optimal policy.\n",
        "*   Further evaluation could involve running multiple simulations with the SARSA optimal policy to calculate average rewards and steps to goal, providing a more robust measure of performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Temporal-Difference Learning (TD(0)) and SARSA in Gridworld\n",
        "-----------------------------------------------------------\n",
        "This script extends the earlier Monte Carlo Gridworld demo by implementing:\n",
        "\n",
        "1) TD(0) Policy Evaluation\n",
        "2) SARSA (on-policy TD control)\n",
        "\n",
        "The environment is the same simple deterministic Gridworld.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, List, Callable\n",
        "\n",
        "Action = int  # 0:UP, 1:RIGHT, 2:DOWN, 3:LEFT\n",
        "State  = Tuple[int, int]\n",
        "\n",
        "@dataclass\n",
        "class Gridworld:\n",
        "    rows: int = 5\n",
        "    cols: int = 5\n",
        "    terminals: Tuple[State, ...] = ((0, 0), (4, 4))\n",
        "    step_cost: float = -1.0\n",
        "    fixed_start: State | None = None\n",
        "    rng_seed: int | None = 42\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.rng = random.Random(self.rng_seed)\n",
        "        self._all_states = [(r, c) for r in range(self.rows) for c in range(self.cols)]\n",
        "        self._non_terminals = [s for s in self._all_states if s not in self.terminals]\n",
        "        self.action_space = [0, 1, 2, 3]\n",
        "\n",
        "    def reset(self) -> State:\n",
        "        if self.fixed_start and self.fixed_start not in self.terminals:\n",
        "            self.s = self.fixed_start\n",
        "        else:\n",
        "            self.s = self.rng.choice(self._non_terminals)\n",
        "        return self.s\n",
        "\n",
        "    def step(self, a: Action) -> Tuple[State, float, bool, dict]:\n",
        "        r, c = self.s\n",
        "        if self.s in self.terminals:\n",
        "            return self.s, 0.0, True, {}\n",
        "        drdc = {0: (-1, 0), 1: (0, 1), 2: (1, 0), 3: (0, -1)}\n",
        "        dr, dc = drdc[a]\n",
        "        nr, nc = r + dr, c + dc\n",
        "        if 0 <= nr < self.rows and 0 <= nc < self.cols:\n",
        "            ns = (nr, nc)\n",
        "        else:\n",
        "            ns = (r, c)\n",
        "        reward = self.step_cost\n",
        "        done = ns in self.terminals\n",
        "        self.s = ns\n",
        "        return ns, reward, done, {}\n",
        "\n",
        "# ==============================\n",
        "# TD(0) Policy Evaluation\n",
        "# ==============================\n",
        "\n",
        "def td0_prediction(env: Gridworld, policy: Callable[[State], Action], episodes: int = 10_000, alpha: float = 0.1, gamma: float = 1.0, rng_seed: int = 0) -> Dict[State, float]:\n",
        "    rng = random.Random(rng_seed)\n",
        "    V = defaultdict(float)\n",
        "    for _ in range(episodes):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            a = policy(s)\n",
        "            ns, r, done, _ = env.step(a)\n",
        "            V[s] += alpha * (r + gamma * V[ns] - V[s])\n",
        "            s = ns\n",
        "    return V\n",
        "\n",
        "# ==============================\n",
        "# SARSA (On-policy TD Control)\n",
        "# ==============================\n",
        "\n",
        "def epsilon_greedy(Q: Dict[State, Dict[Action, float]], s: State, actions: List[Action], epsilon: float, rng: random.Random) -> Action:\n",
        "    if rng.random() < epsilon:\n",
        "        return rng.choice(actions)\n",
        "    return max(actions, key=lambda a: Q[s][a])\n",
        "\n",
        "def sarsa(env: Gridworld, episodes: int = 50_000, alpha: float = 0.1, gamma: float = 1.0, epsilon: float = 0.1, rng_seed: int = 0):\n",
        "    rng = random.Random(rng_seed)\n",
        "    Q = defaultdict(lambda: defaultdict(float))\n",
        "    actions = env.action_space\n",
        "\n",
        "    for _ in range(episodes):\n",
        "        s = env.reset()\n",
        "        a = epsilon_greedy(Q, s, actions, epsilon, rng)\n",
        "        done = False\n",
        "        while not done:\n",
        "            ns, r, done, _ = env.step(a)\n",
        "            na = epsilon_greedy(Q, ns, actions, epsilon, rng) if not done else 0\n",
        "            Q[s][a] += alpha * (r + gamma * Q[ns][na] - Q[s][a])\n",
        "            s, a = ns, na\n",
        "    def greedy_policy(s: State) -> Action:\n",
        "        if s in env.terminals:\n",
        "            return 0\n",
        "        return max(actions, key=lambda a: Q[s][a])\n",
        "    V = {s: max(aq.values()) for s, aq in Q.items()}\n",
        "    return Q, greedy_policy, V\n",
        "\n",
        "# =====================\n",
        "# Pretty-print helpers\n",
        "# =====================\n",
        "ARROWS = {0: \"↑\", 1: \"→\", 2: \"↓\", 3: \"←\"}\n",
        "\n",
        "def print_value_function(V: Dict[State, float], rows: int, cols: int, digits: int = 2) -> None:\n",
        "    for r in range(rows):\n",
        "        print(\" | \".join(f\"{V.get((r,c),0.0): .{digits}f}\" for c in range(cols)))\n",
        "\n",
        "def print_policy(policy: Callable[[State], Action], env: Gridworld):\n",
        "    for r in range(env.rows):\n",
        "        row = []\n",
        "        for c in range(env.cols):\n",
        "            s = (r, c)\n",
        "            if s in env.terminals:\n",
        "                row.append(\"T\")\n",
        "            else:\n",
        "                row.append(ARROWS[policy(s)])\n",
        "        print(\" \".join(row))\n",
        "\n",
        "# =====================\n",
        "# Demo\n",
        "# =====================\n",
        "if __name__ == \"__main__\":\n",
        "    env = Gridworld(rows=5, cols=5, terminals=((0,0),(4,4)), step_cost=-1.0, rng_seed=123)\n",
        "\n",
        "    # Random policy for TD(0) evaluation\n",
        "    rng_eval = random.Random(0)\n",
        "    def random_policy(s: State) -> Action:\n",
        "        if s in env.terminals:\n",
        "            return 0\n",
        "        return rng_eval.choice(env.action_space)\n",
        "\n",
        "    V_td = td0_prediction(env, random_policy, episodes=20_000, alpha=0.1)\n",
        "    print(\"\\n=== TD(0) Value Function under Random Policy ===\")\n",
        "    print_value_function(V_td, env.rows, env.cols)\n",
        "\n",
        "    # SARSA control\n",
        "    Q, pi, V_sarsa = sarsa(env, episodes=100_000, alpha=0.1, epsilon=0.1)\n",
        "    print(\"\\n=== SARSA Learned Policy ===\")\n",
        "    print_policy(pi, env)\n",
        "    print(\"\\n=== SARSA Value Function ===\")\n",
        "    print_value_function(V_sarsa, env.rows, env.cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJFcqJNKxecv",
        "outputId": "4348e801-771b-42c6-afa7-37f6ff777818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TD(0) Value Function under Random Policy ===\n",
            " 0.00 | -20.55 | -34.28 | -39.70 | -41.69\n",
            "-16.22 | -25.65 | -35.07 | -38.13 | -40.18\n",
            "-32.25 | -33.98 | -36.22 | -36.03 | -34.80\n",
            "-39.27 | -38.64 | -35.53 | -30.96 | -20.16\n",
            "-41.43 | -40.22 | -37.15 | -30.90 |  0.00\n",
            "\n",
            "=== SARSA Learned Policy ===\n",
            "T ← ← ← ↓\n",
            "↑ ← ← ← ↓\n",
            "↑ ↑ → ↓ ↓\n",
            "↑ ↑ ↓ ↓ ↓\n",
            "→ → → → T\n",
            "\n",
            "=== SARSA Value Function ===\n",
            " 0.00 | -1.00 | -2.12 | -3.24 | -4.45\n",
            "-1.00 | -2.00 | -3.26 | -4.36 | -3.37\n",
            "-2.15 | -3.05 | -4.44 | -3.21 | -2.22\n",
            "-3.16 | -4.25 | -3.49 | -2.09 | -1.00\n",
            "-4.44 | -3.39 | -2.43 | -1.00 |  0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "d5034f8a",
        "outputId": "2304f982-8f23-42bf-d246-d1ac61973d5b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_value_function_heatmap(V, rows, cols, title=\"Value Function Heatmap\"):\n",
        "    \"\"\"\n",
        "    Plots the value function as a heatmap.\n",
        "\n",
        "    Args:\n",
        "        V: A dictionary representing the value function {state: value}.\n",
        "        rows: Number of rows in the grid.\n",
        "        cols: Number of columns in the grid.\n",
        "        title: Title of the heatmap.\n",
        "    \"\"\"\n",
        "    heatmap_data = np.zeros((rows, cols))\n",
        "    for (r, c), value in V.items():\n",
        "        heatmap_data[r, c] = value\n",
        "\n",
        "    plt.figure(figsize=(cols, rows))\n",
        "    plt.imshow(heatmap_data, cmap='viridis', origin='upper')\n",
        "\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            state = (r, c)\n",
        "            value = V.get(state, 0.0)  # Get value, default to 0 if state not in V\n",
        "            plt.text(c, r, f'{value:.2f}', ha='center', va='center', color='white' if value < np.mean(list(V.values())) else 'black')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xticks(np.arange(cols))\n",
        "    plt.yticks(np.arange(rows))\n",
        "    plt.grid(which='both', color='black', linestyle='-', linewidth=1)\n",
        "    plt.show()\n",
        "\n",
        "# Plot the SARSA Value Function\n",
        "plot_value_function_heatmap(V_sarsa, env.rows, env.cols, title=\"SARSA Learned Value Function Heatmap\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d013cf7"
      },
      "source": [
        "## Visualize Results\n",
        "\n",
        "Visualize the learned value function from the SARSA algorithm as a heatmap."
      ]
    }
  ]
}